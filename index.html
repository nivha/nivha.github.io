<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Niv Haim</title>
  
  <meta name="author" content="Niv Haim's Homepage">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-MVYYQHNEK7"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'G-MVYYQHNEK7');
	</script>
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/favicon.png">
  
  <script>
	const copyToClipboard = str => {
	  const el = document.createElement('textarea');
	  el.value = str;
	  document.body.appendChild(el);
	  el.select();
	  document.execCommand('copy');
	  document.body.removeChild(el);
	  alert("The following bibtextex has been copied to clipboard:\n\n" + el.value);
	};
  </script>

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center"><name>Niv Haim</name></p>
              <p>I am a 5th year Phd student at the <a href="https://www.weizmann.ac.il/pages/">Weizmann Institute of Science</a>, advised by <a href="https://www.weizmann.ac.il/math/irani/">Prof. Michal Irani</a>.
                I work on computer vision and machine learning.
							</p>
							<p> I did my Msc. in theoretical astrophysics, advised by <a href="https://www.weizmann.ac.il/particle/katz/">Prof. Boaz Katz</a>, 
								and worked with <a href="http://www.wisdom.weizmann.ac.il/~ylipman/">Prof. Yaron Lipman</a> on Geometric Deep Learning. 
								I received my BSc. in computer science and physics from the <a href="https://www.technion.ac.il/en/home-2/">Technion</a> (<a href="https://lapidim.cs.technion.ac.il/">Lapidim excellence program</a> alumnus)
							</p>
              <p style="text-align:center">
                <a href="mailto:nivhaa@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.il/citations?user=f7SCiakAAAAJ">Google Scholar</a> &nbsp/&nbsp
				<a href="images/CV.pdf">CV</a> &nbsp/&nbsp
				<a href="https://github.com/nivha">GitHub</a> &nbsp/&nbsp
				<a href="https://linkedin.com/in/niv-haim-736b3b5b">LinkedIn</a> &nbsp/&nbsp
                <a href="https://twitter.com/HaimNiv">Twitter</a>			
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/me.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/me.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
		
		
		<hr/>
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



		  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
					<div class="two" id='sinfusion_vid'>
						<video  width=100% height=100% muted autoplay loop>
							<source src="images/sinfusion.mp4" style="background-color: white;" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</div>
              </div>
              <script type="text/javascript">
					var bibtex_sinfusion = "@article{nikankin2022sinfusion,\n  title={SinFusion: Training Diffusion Models on a Single Image or Video},\n  author={Nikankin, Yaniv and Haim, Niv and Irani, Michal},\n  journal={arXiv preprint arXiv:2211.11743},\n  year={2022}\n}"
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://yanivnik.github.io/sinfusion">
              <papertitle>SinFusion: Training Diffusion Models on a Single Image or Video</papertitle>
              </a>
              <br>
			  	<a href="https://github.com/yanivnik/">Yaniv Nikankin*</a>,
				<strong>Niv Haim*</strong>,
				<a href="https://www.weizmann.ac.il/math/irani/">Michal Irani</a>
              <br>
              <em>International Conference on Machine Learning (ICML)</em>, 2023
              <br>
				<div class="btn-group">
				<button onclick=copyToClipboard(bibtex_sinfusion)>BibTeX</button> / 
				<a href="https://arxiv.org/abs/2211.11743">ArXiv</a> / 
				<a href="https://github.com/yanivnik/sinfusion-code">Code</a> / 
				<a href="https://yanivnik.github.io/sinfusion">Project Page</a> / 
				</div>
              <p>Diffusion models can be trained on a single image or video, giving rise to diverse video generation and extrapolation.</p>
            </td>
		</tr>



		  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
					<div class="two" id='multi_reconstruction_vid'>
					  <img width=100% height=100% src="images/multi_rec.png" style="background-color: white;">
					</div>
              </div>
              <script type="text/javascript">
					var bibtex_multi_reconstruction = "@inproceedings{buzaglo2023reconstructing,\n  title={Reconstructing Training Data from Multiclass Neural Networks},\n  author={Buzaglo, Gon and Haim, Niv and Yehudai, Gilad and Vardi, Gal and others},\n  booktitle={ICLR\n2023 Workshop on Pitfalls of limited data and computation for Trustworthy ML}\n}"
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=SBstNm4OajH">
              <papertitle>Reconstructing Training Data from Multiclass Neural Networks</papertitle>
              </a>
              <br>
				<a href="https://scholar.google.co.il/citations?user=opVT1qkAAAAJ&hl=iw">Gon Buzaglo*</a>,
				<strong>Niv Haim*</strong>,
				<a href="https://scholar.google.co.il/citations?user=opVT1qkAAAAJ&hl=iw">Gilad Yehudai</a>,
				<a href="https://scholar.google.co.il/citations?user=LVk3xE4AAAAJ&hl=en">Gal Vardi</a>,
				<a href="https://www.weizmann.ac.il/math/irani/">Michal Irani</a>
              <br>
              <em>ICLR Workshop on Pitfalls of limited data and computation for Trustworthy ML</em>, 2023
              <br>
				<div class="btn-group">
				<button onclick=copyToClipboard(bibtex_multi_reconstruction)>BibTeX</button> / 
				<a href="https://openreview.net/forum?id=SBstNm4OajH">OpenReview</a> 
				<!-- <a href="https://github.com/nivha/dataset_reconstruction">Code</a> /  -->
				<!-- <a href="https://giladude1.github.io/reconstruction/">Project Page</a> /  -->
				</div>
              <p>Extends reconstruction from Multiclass classifiers and show some intriguing implications of weight decay on the ability to reconstruct training data</p>
            </td>
		</tr>


		  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
					<div class="two" id='reconstruction_vid'>
						<video  width=100% height=100% muted autoplay loop>
							<source src="images/reconstruction.mp4" style="background-color: white;" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</div>
              </div>
              <script type="text/javascript">
					var bibtex_reconstruction = "@inproceedings{NEURIPS2022_90692737,\n author = {Haim, Niv and Vardi, Gal and Yehudai, Gilad and Shamir, Ohad and Irani, Michal},\n booktitle = {Advances in Neural Information Processing Systems},\n editor = {S. Koyejo\nand S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},\n pages = {22911--22924},\n publisher = {Curran Associates, Inc.},\n title = {Reconstructing Training Data From Trained Neural Networks},\n url =\n{https://proceedings.neurips.cc/paper_files/paper/2022/file/906927370cbeb537781100623cca6fa6-Paper-Conference.pdf},\n volume = {35},\n year = {2022}\n}\n"
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://giladude1.github.io/reconstruction/">
              <papertitle>Reconstructing Training Data from Trained Neural Networks</papertitle>
              </a>
              <br>
				<strong>Niv Haim*</strong>,
				<a href="https://scholar.google.co.il/citations?user=LVk3xE4AAAAJ&hl=en">Gal Vardi*</a>,
				<a href="https://scholar.google.co.il/citations?user=opVT1qkAAAAJ&hl=iw">Gilad Yehudai*</a>,
				<a href="https://www.wisdom.weizmann.ac.il/~shamiro/">Ohad Shamir</a>,
				<a href="https://www.weizmann.ac.il/math/irani/">Michal Irani</a>
              <br>
              <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2022 [<b> Oral Presentation </b>]
              <br>
				<div class="btn-group">
				<button onclick=copyToClipboard(bibtex_reconstruction)>BibTeX</button> / 
				<a href="https://arxiv.org/abs/2206.07758">ArXiv</a> / 
				<a href="https://github.com/nivha/dataset_reconstruction">Code</a> / 
				<a href="https://giladude1.github.io/reconstruction/">Project Page</a> / 
				<a href="https://www.youtube.com/watch?v=wrOnp0WfZJ4">Video</a> 
				</div>
              <p>We show that a large portion of the training data can be reconstructed from the parameters of trained MLP binary classifiers. Our method stems from theoretical results about the implicit bias of neural networks trained with gradient descent</p>
            </td>
		</tr>




          <!-- <tr onmouseout="vgpnn_stop()" onmouseover="vgpnn_start()"> -->
		  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
									<div class="two" id='vgpnn_vid'>
										<video  width=100% height=100% muted autoplay loop>
											<source src="images/vgpnn.mp4" style="background-color: white;" type="video/mp4">
											Your browser does not support the video tag.
										</video>
									</div>
              </div>
              <script type="text/javascript">
				var bibtex_vgpnn = "@inproceedings{haim2022diverse,\ntitle={Diverse generation from a single video made possible},\n  author={Haim, Niv and Feinstein, Ben and Granot, Niv and Shocher, Assaf and Bagon, Shai and Dekel, Tali and Irani, Michal},\n  booktitle={European Conference on Computer Vision},\n  pages={491--509},\n  year={2022},\n  organization={Springer}\n}"
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://nivha.github.io/vgpnn/">
              <papertitle>Diverse Generation from a Single Video Made Possible</papertitle>
              </a>
              <br>
				<strong>Niv Haim*</strong>,
				<a href="https://www.semanticscholar.org/author/Ben-Feinstein/4478112">Ben Finestein*</a>,
				<a href="https://scholar.google.com/citations?user=MaDeUsoAAAAJ">Niv Granot</a>,
				<a href="http://www.wisdom.weizmann.ac.il/~/assafsho/">Assaf Shocher</a>,
				<a href="https://www.weizmann.ac.il/math/bagon/home">Shai Bagon</a>,
				<a href="https://www.weizmann.ac.il/math/dekel/">Tali Dekel</a>,
				<a href="https://www.weizmann.ac.il/math/irani/">Michal Irani</a>
              <br>
              <em>European Conference on Computer Vision (ECCV)</em>, 2022
			  <br>
			  <em> (Extended abstract appeared at AI For Content Creation Workshop @ CVPR</em>, 2022)
              <br>
				<div class="btn-group">
				<button onclick=copyToClipboard(bibtex_vgpnn)>BibTeX</button> / 
				<a href="http://arxiv.org/abs/2109.08591">ArXiv</a> / 
				<a href="https://github.com/nivha/single_video_generation">Code</a> /
				<a href="https://nivha.github.io/vgpnn/">Project Page</a>
				</div>
              <p>We generate diverse video samples from a single video using patch-based methods. Our results outperform single-video GANs in visual quality and are orders of magnitude faster to generate</p>
            </td>
		</tr>


          <tr onmouseout="cc_stop()" onmouseover="cc_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cc_vid'>
					<video  width=100% height=100% muted autoplay loop>
						<source src="images/cc.mp4" style="background-color: white;" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</div>
                <img src='images/cc.png' width="160" id="cc_image">
              </div>
              <script type="text/javascript">
			  var bibtex_cc = "@article{shocher2020discrete,\n  title={From discrete to continuous convolution layers},\n  author={Shocher, Assaf and Feinstein, Ben and Haim, Niv and Irani, Michal},\n  journal={arXiv preprint arXiv:2006.11120},\n  year={2020}\n}"
                function cc_start() {
                  document.getElementById('cc_image').style.display = 'none';
				  document.getElementById('cc_vid').style.display = 'inline';
                }
                function cc_stop() {
                  document.getElementById('cc_image').style.display = 'inline';
				  document.getElementById('cc_vid').style.display = 'none';
                }
                cc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2006.11120">
              <papertitle>From Discrete to Continuous Convolution Layers</papertitle>
              </a>
              <br>
				<a href="http://www.wisdom.weizmann.ac.il/~/assafsho/">Assaf Shocher*</a>,
				<a href="https://www.semanticscholar.org/author/Ben-Feinstein/4478112">Ben Finestein*</a>,
				<strong>Niv Haim*</strong>,
				<a href="https://www.weizmann.ac.il/math/irani/">Michal Irani</a>
              <br>
              <em>Preprint</em>, 2020
              <br>
				<div class="btn-group">
				<button onclick=copyToClipboard(bibtex_cc)>BibTeX</button> / 
				<a href="https://arxiv.org/abs/2006.11120">ArXiv</a>
				</div>
              <p>Learning continuous convolution kernels improve translation equivariance and allow test time scales augmentations</p>
            </td>
		</tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/igr.png" alt="clean-usnob" width="160" id="igr_image">
			  <script type="text/javascript">
				var bibtex_igr = "@incollection{icml2020_2086,\n author = {Gropp, Amos and Yariv, Lior and Haim, Niv and Atzmon, Matan and Lipman, Yaron},\n booktitle = {Proceedings of Machine Learning and Systems 2020},\n pages = {3569--3579},\n title = {Implicit Geometric Regularization for Learning Shapes},\n year = {2020}\n}"
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2002.10099">
                <papertitle>Implicit Geometric Regularization for Learning Shapes</papertitle>
              </a>
              <br>
				<a href="https://scholar.google.com/citations?user=m70l1OEAAAAJ">Amos Gropp</a>,
				<a href="https://lioryariv.github.io/">Lior Yariv</a>,
				<strong>Niv Haim</strong>,
				<a href="https://matanatz.github.io/">Matan Atzmon</a>,
				<a href="http://www.wisdom.weizmann.ac.il/~ylipman/">Yaron Lipman</a>
              <br>
              <em>International Conference on Machine Learning (ICML)</em>, 2020
			  <br>
				<div class="btn-group">
				<button onclick=copyToClipboard(bibtex_igr)>BibTeX</button> / 
				<a href="https://arxiv.org/abs/2002.10099">ArXiv</a> /
				<a href="https://github.com/amosgropp/IGR">Code</a> /
				<a href="https://www.youtube.com/watch?v=6cOvBGBQF9g">Video</a>
				<!-- <div class="tooltip">Abstract<span class="tooltiptext">Representing shapes as level sets of neural networks has been recently proved to be useful for different shape analysis and reconstruction tasks. So far, such representations were computed using either: (i) pre-computed implicit shape representations; or (ii) loss functions explicitly defined over the neural level sets. In this paper we offer a new paradigm for computing high fidelity implicit neural representations directly from raw data (i.e., point clouds, with or without normal information). We observe that a rather simple loss function, encouraging the neural network to vanish on the input point cloud and to have a unit norm gradient, possesses an implicit geometric regularization property that favors smooth and natural zero level set surfaces, avoiding bad zero-loss solutions. We provide a theoretical analysis of this property for the linear case, and show that, in practice, our method leads to state of the art implicit neural representations with higher level-of-details and fidelity compared to previous methods.</span></div> -->
				</div>
              <p>Using an "Eikonal regularization" term with implicit neural representation works surprisingly well for modelling complex surfaces</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/controllinglevelsets.png" alt="clean-usnob" width="160" id="controlinglevelsets_image">
			  <script type="text/javascript">
				var bibtex_controllinglevelsets = "@inproceedings{atzmon2019controlling,\n  title={Controlling neural level sets},\n  author={Atzmon, Matan and Haim, Niv and Yariv, Lior and Israelov, Ofer and Maron, Haggai and Lipman, Yaron},\n  booktitle={Advances in Neural Information Processing Systems},\n  pages={2032--2041},\n  year={2019}\n}"
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1905.11911">
                <papertitle>Controlling Neural Level Sets</papertitle>
              </a>
              <br>
				<a href="https://matanatz.github.io/">Matan Atzmon</a>,
				<strong>Niv Haim</strong>,
				<a href="https://lioryariv.github.io/">Lior Yariv</a>,
				Ofer Israelov,
				<a href="https://haggaim.github.io/">Haggai Maron</a>,
				<a href="http://www.wisdom.weizmann.ac.il/~ylipman/">Yaron Lipman</a>
              <br>
              <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2019
			  <br>
				<div class="btn-group">
				<button onclick=copyToClipboard(bibtex_controllinglevelsets)>BibTeX</button> / 
				<a href="https://arxiv.org/abs/1905.11911">ArXiv</a> /
				<a href="https://github.com/matanatz/ControllingNeuralLevelsets">Code</a> /
				<a href="https://github.com/matanatz/ControllingNeuralLevelsets/blob/master/Controlling_Neural_Level_Sets_Poster.pdf">Poster</a>
				<!-- <div class="tooltip">Abstract<span class="tooltiptext">The level sets of neural networks represent fundamental properties such as decision boundaries of classifiers and are used to model non-linear manifold data such as curves and surfaces. Thus, methods for controlling the neural level sets could find many applications in machine learning. In this paper we present a simple and scalable approach to directly control level sets of a deep neural network. Our method consists of two parts: (i) sampling of the neural level sets, and (ii) relating the samples' positions to the network parameters. The latter is achieved by a sample network that is constructed by adding a single fixed linear layer to the original network. In turn, the sample network can be used to incorporate the level set samples into a loss function of interest. We have tested our method on three different learning tasks: improving generalization to unseen data, training networks robust to adversarial attacks, and curve and surface reconstruction from point clouds. For surface reconstruction, we produce high fidelity surfaces directly from raw 3D point clouds. When training small to medium networks to be robust to adversarial attacks we obtain robust accuracy comparable to state-of-the-art methods.</span></div> -->
				</div>
              <p>Making input points differentiable (w.r.t model parameters), and using it for shape modelling, improved robustness to adversrial examples and more</p>
            </td>
          </tr>


		<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/surfacenets.png" alt="clean-usnob" width="160" id="surfacenets_image">
			  <script type="text/javascript">
				var bibtex_surfacenets = "@inproceedings{haim2019surface,\n  title={Surface networks via general covers},\n  author={Haim, Niv and Segol, Nimrod and Ben-Hamu, Heli and Maron, Haggai and Lipman, Yaron},\n  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n  pages={632--641},\n  year={2019}\n}"
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1812.10705">
                <papertitle>Surface Networks via General Covers</papertitle>
              </a>
              <br>
				<strong>Niv Haim*</strong>,
				<a href="https://scholar.google.com/citations?user=dTuhEVsAAAAJ&hl=en">Nimrod Segol*</a>,
				<a href="https://helibenhamu.github.io/">Heli Ben-Hamu</a>,
				<a href="https://haggaim.github.io/">Haggai Maron</a>,
				<a href="http://www.wisdom.weizmann.ac.il/~ylipman/">Yaron Lipman</a>
              <br>
              <em> International Conference on Computer Vision (ICCV)</em>, 2019
			  <br>
				<div class="btn-group">
				<button onclick=copyToClipboard(bibtex_surfacenets)>BibTeX</button> / 
				<a href="https://arxiv.org/abs/1812.10705">ArXiv</a> /
				<a href="https://github.com/nivha/surface_networks_covers">Code</a>
				<!-- <div class="tooltip">Abstract<span class="tooltiptext">Developing deep learning techniques for geometric data is an active and fruitful research area. This paper tackles the problem of sphere-type surface learning by developing a novel surface-to-image representation. Using this representation we are able to quickly adapt successful CNN models to the surface setting. The surface-image representation is based on a covering map from the image domain to the surface. Namely, the map wraps around the surface several times, making sure that every part of the surface is well represented in the image. Differently from previous surface-to-image representations, we provide a low distortion coverage of all surface parts in a single image. Specifically, for the use case of learning spherical signals, our representation provides a low distortion alternative to several popular spherical parameterizations used in deep learning. We have used the surface-to-image representation to apply standard CNN architectures to 3D models as well as spherical signals. We show that our method achieves state of the art or comparable results on the tasks of shape retrieval, shape classification and semantic shape segmentation.</span></div> -->
				</div>
              <p>Transforming 3D shapes to image representation so we can feed them to off-the-shelf CNNs and do classification, human-parts segmentation and more</p>
            </td>
          </tr>


		<!-- <tr onmouseout="extreme_approaches_stop()" onmouseover="extreme_approaches_start()"> -->
		<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='extreme_approaches_vid'>
					<video  width=100% height=100% muted autoplay loop>
						<source src="images/extreme_approaches.mp4" style="background-color: white;" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</div>
                <!-- <img src='images/extreme_approaches.png' width="160" id="extreme_approaches_image"> -->
              </div>
              <script type="text/javascript">
			  var bibtex_extreme_approaches = "@article{haim2018extreme,\n  title={Extreme close approaches in hierarchical triple systems with comparable masses},\n  author={Haim, Niv and Katz, Boaz},\n  journal={Monthly Notices of the Royal Astronomical Society},\n  volume={479},\n  number={3},\n  pages={3155--3166},\n  year={2018},\n  publisher={Oxford University Press}\n}"
                <!-- function extreme_approaches_start() { -->
                  <!-- document.getElementById('extreme_approaches_image').style.display = 'inline'; -->
				  <!-- document.getElementById('extreme_approaches_vid').style.display = 'none'; -->
                <!-- } -->
                <!-- function extreme_approaches_stop() { -->
                  <!-- document.getElementById('extreme_approaches_image').style.display = 'none'; -->
				  <!-- document.getElementById('extreme_approaches_vid').style.display = 'inline'; -->
                <!-- } -->
                <!-- extreme_approaches_stop() -->
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1803.10249">
              <papertitle>Extreme close approaches in hierarchical triple systems with comparable masses</papertitle>
              </a>
              <br>
				<strong>Niv Haim</strong>,
				<a href="https://www.weizmann.ac.il/particle/katz/">Boaz Katz</a>
              <br>
              <em>Monthly Notices of the Royal Astronomical Society</em>, 2018
              <br>
				<div class="btn-group">
				<button onclick=copyToClipboard(bibtex_extreme_approaches)>BibTeX</button> / 
				<a href="https://arxiv.org/abs/1803.10249">ArXiv</a> / 
				<a href="https://github.com/nivha/three_body_integration">Code</a>
				<!-- <div class="tooltip">Abstract<span class="tooltiptext">We study close approaches in hierarchical triple systems with comparable masses using full N-body simulations, motivated by a recent model for type Ia supernovae involving direct collisions of white dwarfs (WDs). For stable hierarchical systems where the inner binary components have equal masses, we show that the ability of the inner binary to achieve very close approaches, where the separation between the components of the inner binary reaches values which are orders of magnitude smaller than the semi-major axis, can be analytically predicted from initial conditions. The rate of close approaches is found to be roughly linear with the mass of the tertiary. The rate increases in systems with unequal inner binaries by a marginal factor of ≲2 for mass ratios 0.5 &#60; m1/m2 &#62; 1 relevant for the inner white-dwarf binaries. For an average tertiary mass of ~0.3M_sun which is representative of typical M-dwarfs, the chance for clean collisions is ~1% setting challenging constraints on the collisional model for type Ia's.</span></div> -->
				</div>
              <p>Ever wondered if your hierarchical three-body system will eventually collide? find out by plugging your initial conditions into our analytical prediction formula (that works with high probability)</p>
            </td>
		</tr>

        </tbody></table>


		<hr/>
		
		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Recorded Talks</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
		  <tr>
            <td width="75%" valign="center">
              <a href="https://www.youtube.com/watch?v=sEsHNEEPegM">Reconstructing Training Data from Trained Classifiers</a> @ Microsoft Data Science Bond
              <br/><br/>
			  <a href="https://www.youtube.com/watch?v=tpcYM0JOZ4s&list=PL_Z2_U9MIJdNgFM7-f2fZ9ZxjVRP_jhJv">Introduction to Adversarial Examples</a> @ <a href="https://dl4cv.github.io/">DL4CV2021</a>
            </td>
          </tr>
        </tbody></table>


		<hr/>
		
		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
		  <tr>
			<td style="width:25%;vertical-align:middle;text-align: center;"><img src="images/weizmann.jpg"><span style="display: inline-block; font-weight: bold;">Weizmann Institute <br/> of Science </span></td>
            <td width="75%" valign="center">
			  <a href="https://nivhaim.medium.com/how-to-give-a-good-students-seminar-presentation-2c060650ba38">Blog Post: How to Give a Good Student Seminar Presentation </a>
			  <br/><br/>
			  Deep Learning for Computer Vision [<a href="https://dl4cv.github.io/DL4CV_Winter22/index.html">Winter 2021</a>, <a href="https://dl4cv.github.io/">Winter 2022</a>]
			  <br/><br/>
              Advanced Topics in Computer Vision and Deep Learning [<a href="http://www.wisdom.weizmann.ac.il/~/vision/courses/2020_2/ADLV/index.html">Spring 2020</a>, <a href="https://weizmannvision.github.io/adlv2021/">Spring 2021</a>, <a href="https://weizmannvision.github.io/adlv2022/">Spring 2022</a>, <a href="https://feinberg.weizmann.ac.il/course/view.php?id=641">Spring 2023</a>]
			  <br/><br/>
              Deep Neural Networks - a Hands-On Challenge [<a href="http://www.wisdom.weizmann.ac.il/~vision/courses/2017_2/DNN%20Challenge/index.html">Spring 2017</a>]
            </td>
          </tr>
        </tbody></table>


		<hr/>
		
		
		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Miscellaneous</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
		  <tr>
            <td width="100%" valign="center">
              I play the violin [<a href="https://www.youtube.com/watch?v=Lnv-VTFBrA8">YouTube</a>]
              <br/><br/>
			  I sometimes write about my travels [<a href="https://mectype.wordpress.com/">blog</a>]
              <br/><br/>
            </td>
          </tr>
        </tbody></table>



		<hr/>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="margin-top:-20px;text-align:center;font-size:small;">
                This website is based on <a href="https://jonbarron.info/">Jon Barron</a>'s <a href="https://github.com/jonbarron/jonbarron_website">homepage template</a>
              </p>
            </td>
          </tr>
        </tbody></table>

		
      </td>
    </tr>
  </table>
</body>

</html>
